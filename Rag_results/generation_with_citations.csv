Query,Model,Answer,Citations,Num_Papers_Cited,Citation_List
What are attention mechanisms in transformer models?,Flan-T5-Base,self-attention computation,"[1] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind...""
[2] Saeefa Rubaiyet Nowmi, Jesus Lopez et al. - ""Critical Evaluation of Quantum Machine Learning for Adversarial Robustness...""
[3] Zengrui Han, Lu Bai et al. - ""WiCo-MG: Wireless Channel Foundation Model for Multipath Generation via Synesthe...""",3,"[1] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind...""; [2] Saeefa Rubaiyet Nowmi, Jesus Lopez et al. - ""Critical Evaluation of Quantum Machine Learning for Adversarial Robustness...""; [3] Zengrui Han, Lu Bai et al. - ""WiCo-MG: Wireless Channel Foundation Model for Multipath Generation via Synesthe..."""
What are attention mechanisms in transformer models?,TinyLlama-1.1B,"Attention mechanisms in transformer models refer to the attention operation that weights the importance of each token in a sequence based on its position in the sequence. This attention operation is a crucial component of transformer models, as it enables the model to learn complex relationships between different components of a sequence.

The attention mechanism in transformer models works by assigning a weight to each token in the sequence based on its position in the sequence. This weight is computed by multiplying the token's positional embedding with its corresponding value in the attention matrix. The attention matrix is a matrix of weights that represents the importance of each token in the sequence. The attention matrix is calculated by multiplying each token's positional embedding with a weight matrix consisting of the contextualized representations of the previous tokens.

The attention mechanism is typically used in the encoder-decoder architecture of transformer models. In the encoder, the positional embeddings are used to embed the input sequence into a fixed-length vector. The attention mechanism then calculates the attention weights for each token in the sequence using the attention matrix. The attention weights are then used to project each token's positional embedding into the hidden representation of the corresponding token in the decoder.","[1] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind...""
[2] Saeefa Rubaiyet Nowmi, Jesus Lopez et al. - ""Critical Evaluation of Quantum Machine Learning for Adversarial Robustness...""
[3] Zengrui Han, Lu Bai et al. - ""WiCo-MG: Wireless Channel Foundation Model for Multipath Generation via Synesthe...""",3,"[1] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind...""; [2] Saeefa Rubaiyet Nowmi, Jesus Lopez et al. - ""Critical Evaluation of Quantum Machine Learning for Adversarial Robustness...""; [3] Zengrui Han, Lu Bai et al. - ""WiCo-MG: Wireless Channel Foundation Model for Multipath Generation via Synesthe..."""
How do large language models process natural language?,Flan-T5-Base,vec,"[1] Giuseppe Matera - ""Corporate Earnings Calls and Analyst Beliefs...""
[2] Amir Hossein Kargaran, Nafiseh Nikeghbal et al. - ""Insights from the ICLR Peer Review and Rebuttal Process...""
[3] Basel Shbita, Farhan Ahmed et al. - ""MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Gen...""
[4] Shan Shan - ""Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causa...""",4,"[1] Giuseppe Matera - ""Corporate Earnings Calls and Analyst Beliefs...""; [2] Amir Hossein Kargaran, Nafiseh Nikeghbal et al. - ""Insights from the ICLR Peer Review and Rebuttal Process...""; [3] Basel Shbita, Farhan Ahmed et al. - ""MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Gen...""; [4] Shan Shan - ""Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causa..."""
How do large language models process natural language?,TinyLlama-1.1B,"Large-scale language models, such as BERT, are trained on a vast corpus of text and can process natural language with high proficiency, thanks to advancements in natural language processing (NLP) techniques. Specifically, these models use a combination of recurrent neural networks (RNNs), Transformer architecture, and large-scale pre-training on large corpora.

The RNN component in these models is responsible for processing temporal context and generating sequence outputs, such as sentences or paragraphs. The Transformer architecture in BERT, for instance, uses self-attention mechanisms to capture the relationships between tokens in a sequence and generate a final output.

The BERT model was first introduced in 2019 and has since been trained on a variety of datasets, including the Common Crawl corpus, the Google News corpus, and the IMDB movie review corpus. The model's performance on these datasets has consistently exceeded that of state-of-the-art human language models, such as the GPT-3 model.

Large-scale language models' ability to process natural language with high proficiency is not limited to the accuracy of their predictions, but","[1] Giuseppe Matera - ""Corporate Earnings Calls and Analyst Beliefs...""
[2] Amir Hossein Kargaran, Nafiseh Nikeghbal et al. - ""Insights from the ICLR Peer Review and Rebuttal Process...""
[3] Basel Shbita, Farhan Ahmed et al. - ""MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Gen...""
[4] Shan Shan - ""Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causa...""",4,"[1] Giuseppe Matera - ""Corporate Earnings Calls and Analyst Beliefs...""; [2] Amir Hossein Kargaran, Nafiseh Nikeghbal et al. - ""Insights from the ICLR Peer Review and Rebuttal Process...""; [3] Basel Shbita, Farhan Ahmed et al. - ""MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Gen...""; [4] Shan Shan - ""Reflexive Evidence-Based Multimodal Learning for Clean Energy Transitions: Causa..."""
What is retrieval augmented generation?,Flan-T5-Base,modality,"[1] Wenhan Yu, Wang Chen et al. - ""BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning...""
[2] Linyin Luo, Yujuan Ding et al. - ""HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generat...""
[3] Huixiang Zhang, Mahzabeen Emu - ""Quantum-Guided Test Case Minimization for LLM-Based Code Generation...""
[4] Urjitkumar Patel, Fang-Chun Yeh et al. - ""AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning...""",4,"[1] Wenhan Yu, Wang Chen et al. - ""BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning...""; [2] Linyin Luo, Yujuan Ding et al. - ""HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generat...""; [3] Huixiang Zhang, Mahzabeen Emu - ""Quantum-Guided Test Case Minimization for LLM-Based Code Generation...""; [4] Urjitkumar Patel, Fang-Chun Yeh et al. - ""AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning..."""
What is retrieval augmented generation?,TinyLlama-1.1B,"Retrieval augmented generation (RAG) is a technique for improving the performance of document retrieval and question answering using a combination of multiple modalities. In RAG, each passage in a corpus is represented by a vector in the feature space, which is computed as the concatenation of the text-related embeddings for the passage and the image-related embeddings for the same passage. This approach allows for effective representation of each passage, which can be used for similarity comparison and ranking.

RAG has been proposed in multiple papers, including [1], where the authors have shown how to use RAG to improve the performance of multimodal document retrieval using a multimodal encoder-decoder architecture. In [2], the authors propose a novel approach for RAG, which allows for more efficient computation of the similarity scores between queries and documents while preserving their underlying semantics.

Some of the key contributions of RAG include its ability to handle multiple modalities simultaneously, its ability to capture the semantic and syntactic differences between different modalities, its ability to learn from a diverse collection of documents, and its ability to improve the performance of document retrieval and question answering tasks.

Re","[1] Wenhan Yu, Wang Chen et al. - ""BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning...""
[2] Linyin Luo, Yujuan Ding et al. - ""HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generat...""
[3] Huixiang Zhang, Mahzabeen Emu - ""Quantum-Guided Test Case Minimization for LLM-Based Code Generation...""
[4] Urjitkumar Patel, Fang-Chun Yeh et al. - ""AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning...""",4,"[1] Wenhan Yu, Wang Chen et al. - ""BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning...""; [2] Linyin Luo, Yujuan Ding et al. - ""HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generat...""; [3] Huixiang Zhang, Mahzabeen Emu - ""Quantum-Guided Test Case Minimization for LLM-Based Code Generation...""; [4] Urjitkumar Patel, Fang-Chun Yeh et al. - ""AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning..."""
Explain the benefits of pre-training in NLP,Flan-T5-Base,pre-training provides an explicit and share- able blueprint for an analysis,"[1] Yves Pauli, Jan-Bernard Marsman et al. - ""Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis...""
[2] Randa Zarnoufi - ""MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment An...""
[3] Mohammad Cheraghinia, Eli De Poorter et al. - ""Lightweight Foundation Model for Wireless Time Series Downstream Tasks on Edge D...""",3,"[1] Yves Pauli, Jan-Bernard Marsman et al. - ""Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis...""; [2] Randa Zarnoufi - ""MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment An...""; [3] Mohammad Cheraghinia, Eli De Poorter et al. - ""Lightweight Foundation Model for Wireless Time Series Downstream Tasks on Edge D..."""
Explain the benefits of pre-training in NLP,TinyLlama-1.1B,"Pre-training in Natural Language Processing (NLP) refers to pre-processing and pre-processing steps that are carried out before building a model or using a pre-trained model. This pre-training process helps in improving the performance of the model by learning the underlying patterns and structure of the dataset. Pre-training is particularly beneficial for NLP tasks that involve language modeling, such as sentiment analysis, machine translation, and question answering.

Some of the benefits of pre-training in NLP include:

1. Improved generalization: Pre-training helps to build a strong base model by learning the underlying patterns and structures of the dataset. This allows the model to generalize better to new data sets and improve its performance on previously unseen tasks.

2. Reduced training time: Pre-training can reduce the time required for training the model by up to 70% compared to a fully trained model. This is because pre-training involves fewer optimization steps and can be performed in parallel with training.

3. Improved model interpretability: Pre-training can help in understanding the underlying patterns and structures of the dataset, which can be useful for debugging and model tuning. This","[1] Yves Pauli, Jan-Bernard Marsman et al. - ""Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis...""
[2] Randa Zarnoufi - ""MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment An...""
[3] Mohammad Cheraghinia, Eli De Poorter et al. - ""Lightweight Foundation Model for Wireless Time Series Downstream Tasks on Edge D...""",3,"[1] Yves Pauli, Jan-Bernard Marsman et al. - ""Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis...""; [2] Randa Zarnoufi - ""MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment An...""; [3] Mohammad Cheraghinia, Eli De Poorter et al. - ""Lightweight Foundation Model for Wireless Time Series Downstream Tasks on Edge D..."""
How does BERT differ from GPT models?,Flan-T5-Base,These models have been widely applied in variou,"[1] Anqi Wang, Zhengyi Li et al. - ""DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning i...""
[2] Guoqiang Liang, Jingqian Gong et al. - ""The Empowerment of Science of Science by Large Language Models: New Tools and Me...""
[3] Robert Kubinec, Aseem Mahajan - ""Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertisin...""
[4] Ruixin Zhang, Jon Donnelly et al. - ""It's LIT! Reliability-Optimized LLMs with Inspectable Tools...""",4,"[1] Anqi Wang, Zhengyi Li et al. - ""DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning i...""; [2] Guoqiang Liang, Jingqian Gong et al. - ""The Empowerment of Science of Science by Large Language Models: New Tools and Me...""; [3] Robert Kubinec, Aseem Mahajan - ""Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertisin...""; [4] Ruixin Zhang, Jon Donnelly et al. - ""It's LIT! Reliability-Optimized LLMs with Inspectable Tools..."""
How does BERT differ from GPT models?,TinyLlama-1.1B,"BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer) are two different models used for natural language processing (NLP) tasks, specifically for generating human-like text. BERT is a sequence-to-sequence model designed for language translation tasks, while GPT is a generative model that can generate text from a pre-trained language model (LM).

One key difference between BERT and GPT is their input format. BERT takes a sequence of input tokens as input and produces a sequence of hidden states, while GPT takes a sequence of text inputs and generates a sequence of hidden states that represent the probability of generating each token. BERT is specifically designed for language translation tasks, while GPT can generate text in different styles and contexts, including natural language generation (NLG).

In terms of usage, BERT is primarily used for language translation, while GPT is widely used for NLP tasks that require generating human-like text, such as chatbots, text-to-speech, and writing style transfer. Additionally, BERT is often used in research and academic contexts, while GPT is more commonly used in","[1] Anqi Wang, Zhengyi Li et al. - ""DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning i...""
[2] Guoqiang Liang, Jingqian Gong et al. - ""The Empowerment of Science of Science by Large Language Models: New Tools and Me...""
[3] Robert Kubinec, Aseem Mahajan - ""Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertisin...""
[4] Ruixin Zhang, Jon Donnelly et al. - ""It's LIT! Reliability-Optimized LLMs with Inspectable Tools...""",4,"[1] Anqi Wang, Zhengyi Li et al. - ""DesignerlyLoop: Bridging the Cognitive Gap through Visual Node-Based Reasoning i...""; [2] Guoqiang Liang, Jingqian Gong et al. - ""The Empowerment of Science of Science by Large Language Models: New Tools and Me...""; [3] Robert Kubinec, Aseem Mahajan - ""Fifty Shades of Greenwashing: The Political Economy of Climate Change Advertisin...""; [4] Ruixin Zhang, Jon Donnelly et al. - ""It's LIT! Reliability-Optimized LLMs with Inspectable Tools..."""
What are the main challenges in neural machine translation?,Flan-T5-Base,Continual Reinforcement Learning for Cyber-Physical Systems,"[1] Simon Kl端ttermann - ""Towards Evolutionary Optimization Using the Ising Model...""
[2] Kim N. Nolle, Ivana Dusparic et al. - ""Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and...""
[3] Haizhou Wen, He Li et al. - ""Reconstruction of three-dimensional shapes of normal and disease-related erythro...""
[4] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind...""",4,"[1] Simon Kl端ttermann - ""Towards Evolutionary Optimization Using the Ising Model...""; [2] Kim N. Nolle, Ivana Dusparic et al. - ""Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and...""; [3] Haizhou Wen, He Li et al. - ""Reconstruction of three-dimensional shapes of normal and disease-related erythro...""; [4] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind..."""
What are the main challenges in neural machine translation?,TinyLlama-1.1B,"The main challenges in neural machine translation (NMT) include:

1. Model capacity: The size and complexity of NMT models have increased with the growth of natural language data and the difficulty of pretraining models on large-scale datasets. This has led to an increasing need for more powerful and efficient NMT systems.

2. Learning-to-rank: Ranking the best NMT translations among candidates generated by different models is a challenging task. This is especially true for large-scale datasets where models need to provide accurate translations in a timely manner.

3. Domain adaptation: Adapting NMT models to different domains, such as source and target languages, is a common problem in natural language processing. This is especially important in NMT for languages with different syntax and semantics.

4. Pretrained models: Pre-trained language models, such as BERT and RoBERTa, have shown great success in NMT. However, these models require significant resources, making it challenging to train and evaluate them on small datasets.

5. Noisy data: Noisy data, such as language-specific stop words, can adversely affect NMT performance. Addressing this issue","[1] Simon Kl端ttermann - ""Towards Evolutionary Optimization Using the Ising Model...""
[2] Kim N. Nolle, Ivana Dusparic et al. - ""Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and...""
[3] Haizhou Wen, He Li et al. - ""Reconstruction of three-dimensional shapes of normal and disease-related erythro...""
[4] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind...""",4,"[1] Simon Kl端ttermann - ""Towards Evolutionary Optimization Using the Ising Model...""; [2] Kim N. Nolle, Ivana Dusparic et al. - ""Continual Reinforcement Learning for Cyber-Physical Systems: Lessons Learned and...""; [3] Haizhou Wen, He Li et al. - ""Reconstruction of three-dimensional shapes of normal and disease-related erythro...""; [4] Yu Sha, Ningtao Liu et al. - ""A Review of Machine Learning for Cavitation Intensity Recognition in Complex Ind..."""
How do embeddings capture semantic meaning?,Flan-T5-Base,en- code each modality separately,"[1] Hyo-Jeong Jang, Hye-Bin Shin et al. - ""Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems...""
[2] Fuwei Zhang, Xiaoyu Liu et al. - ""Multi-Aspect Cross-modal Quantization for Generative Recommendation...""
[3] Zanxu Wang, Homayoon Beigi - ""Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity...""",3,"[1] Hyo-Jeong Jang, Hye-Bin Shin et al. - ""Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems...""; [2] Fuwei Zhang, Xiaoyu Liu et al. - ""Multi-Aspect Cross-modal Quantization for Generative Recommendation...""; [3] Zanxu Wang, Homayoon Beigi - ""Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity..."""
How do embeddings capture semantic meaning?,TinyLlama-1.1B,"Embeddings are a type of artificial neural network that capture the relationship between text and the meaning it represents. They do so by encoding the meaning of a sentence or paragraph into a vector or matrix, which represents the way words are related to each other. In the context of multimodal human-agent interaction, embeddings are used to capture semantic meaning, which refers to the meaning or meaningful associations conveyed by a word or concept.

One way that embeddings capture semantic meaning is through their ability to represent the relationships between words. For example, a word embedding representation can be used to map the meaning of a word to a different space, which is then used to represent the relationships between words. This allows the system to understand the meaning of a phrase or sentence by considering the relationships between words.

Another way that embeddings capture semantic meaning is through their ability to represent the context of a phrase or sentence. For example, a word embedding representation can be used to map the meaning of a word to a specific context, such as a sentence or a larger piece of text. This allows the system to understand the context of a phrase or sentence and make meaningful inferences based on the relationships between words.

Over","[1] Hyo-Jeong Jang, Hye-Bin Shin et al. - ""Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems...""
[2] Fuwei Zhang, Xiaoyu Liu et al. - ""Multi-Aspect Cross-modal Quantization for Generative Recommendation...""
[3] Zanxu Wang, Homayoon Beigi - ""Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity...""",3,"[1] Hyo-Jeong Jang, Hye-Bin Shin et al. - ""Cross-Modal Consistency-Guided Active Learning for Affective BCI Systems...""; [2] Fuwei Zhang, Xiaoyu Liu et al. - ""Multi-Aspect Cross-modal Quantization for Generative Recommendation...""; [3] Zanxu Wang, Homayoon Beigi - ""Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity..."""
What is the role of positional encoding in transformers?,Flan-T5-Base,captures essential spatial information about the environment,"[1] Mauro Larrat, Claudomiro Sales - ""A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognitio...""
[2] Mingyang Feng, Shaoyuan Li et al. - ""RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer...""
[3] Nathan M. Roberts, Xiaosong Du - ""Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory De...""
[4] Loveneet Saini, Hasan Tercan et al. - ""Graph Query Networks for Object Detection with Automotive Radar...""",4,"[1] Mauro Larrat, Claudomiro Sales - ""A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognitio...""; [2] Mingyang Feng, Shaoyuan Li et al. - ""RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer...""; [3] Nathan M. Roberts, Xiaosong Du - ""Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory De...""; [4] Loveneet Saini, Hasan Tercan et al. - ""Graph Query Networks for Object Detection with Automotive Radar..."""
What is the role of positional encoding in transformers?,TinyLlama-1.1B,"In the context of transformer models, positional encoding is a technique used to account for the positional information of the input sequence in the model's representation. This technique involves adding a series of linearly spaced positions to the input sequence, with the relative position of each position represented by a unit-length vector. The positional encoding helps to preserve the spatial relationships between the elements within the sequence and enables the transformer model to capture relevant contextual information.

In the context of transformer architectures, positional encoding plays a critical role in the Transformer Encoder, which comprises multiple layers with multi-head self-attention and feed-forward networks. The Transformer Encoder is responsible for encoding the input sequence into a high-dimensional feature representation that captures essential spatial information about the environment. The positional encoding helps to align the feature representations with the spatial structure of the input sequence, enabling the Transformer to better understand the contextual information.

In summary, positional encoding plays a critical role in transformer architectures by preserving the spatial relationships between the elements within the sequence and enabling the transformer to capture relevant contextual information.","[1] Mauro Larrat, Claudomiro Sales - ""A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognitio...""
[2] Mingyang Feng, Shaoyuan Li et al. - ""RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer...""
[3] Nathan M. Roberts, Xiaosong Du - ""Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory De...""
[4] Loveneet Saini, Hasan Tercan et al. - ""Graph Query Networks for Object Detection with Automotive Radar...""",4,"[1] Mauro Larrat, Claudomiro Sales - ""A Multimodal Transformer Approach for UAV Detection and Aerial Object Recognitio...""; [2] Mingyang Feng, Shaoyuan Li et al. - ""RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer...""; [3] Nathan M. Roberts, Xiaosong Du - ""Transformer-Guided Deep Reinforcement Learning for Optimal Takeoff Trajectory De...""; [4] Loveneet Saini, Hasan Tercan et al. - ""Graph Query Networks for Object Detection with Automotive Radar..."""
